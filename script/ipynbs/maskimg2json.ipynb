{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "903d0b11",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f3410f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-866fc5121869>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mndimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmeasure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegmentation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclear_border\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreshold_otsu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "import collections as cl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from skimage import measure\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.filters import threshold_otsu\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "from PIL import Image\n",
    "import json\n",
    "import cv2\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "# print(\"finish import\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3edb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info():\n",
    "    tmp = cl.OrderedDict()\n",
    "    tmp[\"description\"] = \"detect crater image num = 10000 For valid\"\n",
    "    tmp[\"unity_info\"] = \"Random seed = 656441\"\n",
    "    tmp[\"url\"] = \"https://www.brain.kyutech.ac.jp/~tamukoh/\"\n",
    "    tmp[\"version\"] = \"3.0\"\n",
    "    tmp[\"year\"] = 2021\n",
    "    tmp[\"contributor\"] = \"yuga yano\"\n",
    "    tmp[\"data_created\"] = \"2021/10/13\"\n",
    "    tmp[\"image_size\"] = \"550 x 550\"\n",
    "    return tmp\n",
    "\n",
    "def licenses():\n",
    "    tmp = cl.OrderedDict()\n",
    "    tmp[\"id\"] = 1\n",
    "    tmp[\"url\"] = \"https://www.brain.kyutech.ac.jp/~tamukoh/\"\n",
    "    tmp[\"name\"] = \"Kyutech.Tamlab.yano\"\n",
    "    return tmp\n",
    "\n",
    "def categories():\n",
    "    tmps = []\n",
    "    sup = [\"crater\"]\n",
    "    cat = [\"crater\"]\n",
    "    for i in range(len(sup)):\n",
    "        tmp = cl.OrderedDict()\n",
    "        tmp[\"id\"] = i+1\n",
    "        tmp[\"name\"] = cat[i]\n",
    "        tmp[\"supercategory\"] = sup[i]\n",
    "        tmps.append(tmp)\n",
    "    return tmps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bdf541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images(rgb_path, ignore, height, width):\n",
    "    tmps = []\n",
    "    files = glob.glob(rgb_path + \"/*.png\")\n",
    "    files.sort()\n",
    "    \n",
    "    image_id = 0\n",
    "    for i, file in enumerate(files):\n",
    "        \n",
    "        if i in ignore:\n",
    "            pass\n",
    "        else:\n",
    "            tmp = cl.OrderedDict()\n",
    "            tmp[\"license\"] = 1\n",
    "            tmp[\"id\"] = image_id\n",
    "            tmp[\"file_name\"] = os.path.basename(file)\n",
    "            tmp[\"width\"] = width\n",
    "            tmp[\"height\"] = height\n",
    "            tmp[\"date_captured\"] = \"\"\n",
    "            tmp[\"coco_url\"] = \"dummy_words\"\n",
    "            tmp[\"flickr_url\"] = \"dummy_words\"\n",
    "            tmps.append(tmp)\n",
    "            image_id += 1\n",
    "    return tmps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2171da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub_mask_annotation_con(contour, image_id, category_id, annotation_id, is_crowd, poly, area):\n",
    "    # Find contours (boundary lines) around each sub-mask\n",
    "    # Note: there could be multiple contours if the object\n",
    "    # is partially occluded. (E.g. an elephant behind a tree)\n",
    "#     contours = measure.find_contours(sub_mask, 0.5)\n",
    "\n",
    "    segmentations = []\n",
    "    polygons = []\n",
    "#     for contour in contours:\n",
    "        # Flip from (row, col) representation to (x, y)\n",
    "        # and subtract the padding pixel\n",
    "#     for i in range(len(contour)):\n",
    "#         row, col = contour[i]\n",
    "#         contour[i] = (col, row)\n",
    "\n",
    "    # Make a polygon and simplify it\n",
    "#     poly = Polygon(contour)\n",
    "#     poly = poly.simplify(1.0, preserve_topology=False)\n",
    "    polygons.append(poly)\n",
    "    segmentation = np.array(poly.exterior.coords).ravel().tolist()\n",
    "    segmentations.append(segmentation)\n",
    "\n",
    "    # Combine the polygons to calculate the bounding box and area\n",
    "    multi_poly = MultiPolygon(polygons)\n",
    "    x, y, max_x, max_y = multi_poly.bounds\n",
    "    width = max_x - x\n",
    "    height = max_y - y\n",
    "    bbox = (x, y, width, height)\n",
    "#     area = multi_poly.area\n",
    "\n",
    "    annotation = {\n",
    "        'segmentation': segmentations,\n",
    "        'iscrowd': is_crowd,\n",
    "        'image_id': image_id,\n",
    "        'category_id': category_id,\n",
    "        'id': annotation_id,\n",
    "        'bbox': bbox,\n",
    "        'area': area\n",
    "    }\n",
    "\n",
    "    return annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23a706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotations(mask_path, thresh_areasize):\n",
    "    print(\"===== make annotation start =====\")\n",
    "    mask_images = glob.glob(mask_path + \"/*.png\")\n",
    "    mask_images.sort()\n",
    "\n",
    "    # Define which colors match which categories in the images\n",
    "    houseplant_id, book_id, bottle_id, lamp_id = [1, 2, 3, 4]\n",
    "    crater_id = 1\n",
    "    category_ids = {\n",
    "        1: {\n",
    "            '(77, 25, 255)': crater_id,\n",
    "            '(0, 0, 255)': book_id,\n",
    "        },\n",
    "        2: {\n",
    "            '(255, 255, 0)': bottle_id,\n",
    "            '(255, 0, 128)': book_id,\n",
    "            '(255, 100, 0)': lamp_id,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    is_crowd = 0\n",
    "\n",
    "    # These ids will be automatically increased as we go\n",
    "    annotation_id = 0\n",
    "    image_id = 0\n",
    "    \n",
    "    rgb_image_id = 0\n",
    "    # クレータが存在しない画像をデータセットから除外するため，除外する画像のidをリストで保存する\n",
    "    ignore = []\n",
    "    \n",
    "    # Create the annotations\n",
    "    annotations = []\n",
    "    for mask_image_path in mask_images:\n",
    "        mask_image_color = Image.open(mask_image_path).convert('RGB')\n",
    "        mask_image_gray = cv2.imread(mask_image_path, 0)\n",
    "        base_mask_image_name = os.path.basename(mask_image_path)\n",
    "        contours = measure.find_contours(mask_image_gray, 0.5)\n",
    "\n",
    "        # クレーターが存在しない画像が読み込まれた場合\n",
    "        if len(contours) == 0:\n",
    "            print(\"[warning_1]\", base_mask_image_name, \"no annotation\")\n",
    "            ignore.append(rgb_image_id)\n",
    "            rgb_image_id += 1\n",
    "            continue\n",
    "    \n",
    "        # 領域ごとに，ポリゴンとBboxを算出する\n",
    "        for contour in contours:\n",
    "            for i in range(len(contour)):\n",
    "                row, col = contour[i]\n",
    "                # x, yの入れ替えと小数点以下を丸める処理\n",
    "                contour[i] = (round(col), round(row))\n",
    "        \n",
    "            polygons = []\n",
    "            category_id = 1 # 今回はクラスがクレータしかないので，1で固定\n",
    "            \n",
    "            # ポリゴンによってエラーが出ることがあるので，try exceptで対応（エラーの原因不明）\n",
    "            try:\n",
    "                poly = Polygon(contour)\n",
    "                poly = poly.simplify(1.0, preserve_topology=False)\n",
    "#                 print(poly)\n",
    "                \n",
    "                # polygonが計算できた時のみ\"annotations\"に追加する\n",
    "                if poly.is_empty == False:\n",
    "                    polygons.append(poly)\n",
    "                    multi_poly = MultiPolygon(polygons)\n",
    "                    area = multi_poly.area\n",
    "#                     print(area)\n",
    "                    if area < thresh_areasize: # 小さすぎるクレーターのアノテーションデータは無視する\n",
    "#                         print(\"[warning_3]\", base_mask_image_name, \"area size is too small. skipping!\")\n",
    "                        pass\n",
    "                    else:\n",
    "                        annotation = create_sub_mask_annotation_con(contour, image_id, category_id, annotation_id, is_crowd, poly, area)\n",
    "                        annotations.append(annotation)\n",
    "                        annotation_id += 1\n",
    "            except:\n",
    "                print(\"[warning_2]\", base_mask_image_name, \"skipping the counter\")\n",
    "        \n",
    "        image_id += 1\n",
    "        rgb_image_id += 1\n",
    "        if image_id % 100 == 0:\n",
    "            print(\"progress: \", image_id)\n",
    "            \n",
    "    print(len(mask_images),\"個のファイルのうち\" ,len(ignore), \"個はクレータが存在しないため無視しました\")\n",
    "    print(\"最終的なデータ数は\", len(mask_images)-len(ignore), \"です\")\n",
    "    print(\"===== create annotation complete!! =====\")\n",
    "#     print(ignore)\n",
    "    return annotations, ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6220d188",
   "metadata": {},
   "source": [
    "# 実行関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cfadba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # フォルダパス\n",
    "    base_path = \"/home/yuga/.config/unity3d/DefaultCompany/PerceptionURP/valid/\"\n",
    "#     base_path = \"/home/yuga/.config/unity3d/DefaultCompany/PerceptionURP/tests/ZED_720p/\"\n",
    "    \n",
    "    mask_path = base_path + \"semas\"\n",
    "    rgb_path = base_path + \"images\"\n",
    "    \n",
    "    # データの画像サイズ\n",
    "    height = 550\n",
    "    width = 550\n",
    "    \n",
    "    # 無視するアノテーションのエリアサイズ\n",
    "    # 小さすぎるクレータのアノテーションデータはノイズになっているが可能性あるため除外する\n",
    "    thresh_areasize = 1\n",
    "    \n",
    "    query_list = [\"info\", \"licenses\", \"images\", \"annotations\", \"categories\", \"segment_info\"]\n",
    "    js = cl.OrderedDict()\n",
    "    for i in range(len(query_list)):\n",
    "        tmp = \"\"\n",
    "        # Info\n",
    "        if query_list[i] == \"info\":\n",
    "            tmp = info()\n",
    "\n",
    "        # licenses\n",
    "        elif query_list[i] == \"licenses\":\n",
    "            tmp = licenses()\n",
    "\n",
    "#         elif query_list[i] == \"images\":\n",
    "#             tmp = images(rgb_path)\n",
    "\n",
    "# fix me\n",
    "        elif query_list[i] == \"annotations\":\n",
    "            tmp, ignore = annotations(mask_path, thresh_areasize)\n",
    "            tmp_img = \"\"\n",
    "            tmp_img = images(rgb_path, ignore, height, width)\n",
    "            js[query_list[i-1]] = tmp_img\n",
    "\n",
    "        elif query_list[i] == \"categories\":\n",
    "            tmp = categories()\n",
    "\n",
    "        # save it\n",
    "        js[query_list[i]] = tmp\n",
    "\n",
    "    print(\"finish\")\n",
    "#     print(js[\"images\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a13e2e",
   "metadata": {},
   "source": [
    "# json書き込み\n",
    "- 一回だけだと書き込めないバグがあるので，二回実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094a37d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write\n",
    "# 書き出すjsonのファイル名\n",
    "json_name = base_path + \"valid_moon.json\"\n",
    "\n",
    "fw = open(json_name, 'w')\n",
    "json.dump(js, fw)\n",
    "# json.dump(js, fw, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc3135e",
   "metadata": {},
   "source": [
    "# テスト用\n",
    "- 書き込みが成功していれば，categoriesを確認することができる\n",
    "- errorが出れば，書き込みに失敗しているので，書き込みをもう一回実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd565be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_name) as f:\n",
    "    df = json.load(f)\n",
    "# print(len(df[\"images\"]))\n",
    "print(\"last_image_id =\", df[\"images\"][-1][\"id\"])\n",
    "print(\"info = \", df[\"info\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eacf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"train_moon.json\") as f:\n",
    "#     df = json.load(f)\n",
    "print(df[\"annotations\"][13][\"segmentation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942703ee",
   "metadata": {},
   "source": [
    "# 必要なし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4542cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = \"\"\n",
    "tmp = info()\n",
    "js[0] = tmp\n",
    "print(js[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ebb2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plant_book_mask_image = Image.open('/home/yuga/.config/unity3d/DefaultCompany/PerceptionURP/train/semas/segmentation_2.png').convert('RGB')\n",
    "# bottle_book_mask_image = Image.open('/home/yuga/.config/unity3d/DefaultCompany/PerceptionURP/train/semas/segmentation_3.png').convert('RGB')\n",
    "\n",
    "plant_book_mask_image = Image.open('images/plant_book_mask.png')\n",
    "bottle_book_mask_image = Image.open('images/bottle_book_mask.png')\n",
    "\n",
    "mask_images = [plant_book_mask_image, bottle_book_mask_image]\n",
    "\n",
    "# Define which colors match which categories in the images\n",
    "houseplant_id, book_id, bottle_id, lamp_id = [1, 2, 3, 4]\n",
    "category_ids = {\n",
    "    1: {\n",
    "        '(0, 255, 0)': houseplant_id,\n",
    "        '(0, 0, 255)': book_id,\n",
    "    },\n",
    "    2: {\n",
    "        '(255, 255, 0)': bottle_id,\n",
    "        '(255, 0, 128)': book_id,\n",
    "        '(255, 100, 0)': lamp_id,\n",
    "    }\n",
    "}\n",
    "\n",
    "is_crowd = 0\n",
    "\n",
    "# These ids will be automatically increased as we go\n",
    "annotation_id = 1\n",
    "image_id = 1\n",
    "\n",
    "# Create the annotations\n",
    "annotations = []\n",
    "for mask_image in mask_images:\n",
    "    print(mask_image)\n",
    "    sub_masks = create_sub_masks(mask_image)\n",
    "    for color, sub_mask in sub_masks.items():\n",
    "        category_id = category_ids[image_id][color]\n",
    "        print(sub_mask)\n",
    "        plt.imshow(sub_mask)\n",
    "        plt.show(sub_mask)\n",
    "        annotation = create_sub_mask_annotation(sub_mask, image_id, category_id, annotation_id, is_crowd)\n",
    "        annotations.append(annotation)\n",
    "        annotation_id += 1\n",
    "    image_id += 1\n",
    "\n",
    "print(json.dumps(annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb97016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from skimage import measure\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.filters import threshold_otsu\n",
    "plt.rcParams['font.size']=12\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "#make data\n",
    "n = 6\n",
    "s = 256\n",
    "im = np.zeros((s, s))\n",
    "points = (s*np.random.random((2, n**2))).astype(int)\n",
    "im[points[0], points[1]] = 1\n",
    "im = ndimage.gaussian_filter(im, sigma=s/(5.*n))\n",
    "\n",
    "thresh = threshold_otsu(im)\n",
    "im = im > thresh \n",
    "im = clear_border(im)\n",
    "\n",
    "print(im)\n",
    "contours = measure.find_contours(im, 0.5)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "for n, contour in enumerate(contours):\n",
    "    ax.plot(contour[:, 1], contour[:, 0], linewidth=4)\n",
    "    ax.text(contour[0, 1], contour[0, 0],n)\n",
    "    \n",
    "ax.imshow(im, cmap=plt.cm.cividis, interpolation='gaussian',origin='lower',alpha=0.5)\n",
    "plt.savefig('findcontours05.png',dpi=100)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad2cb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub_mask_annotation(sub_mask, image_id, category_id, annotation_id, is_crowd):\n",
    "    # Find contours (boundary lines) around each sub-mask\n",
    "    # Note: there could be multiple contours if the object\n",
    "    # is partially occluded. (E.g. an elephant behind a tree)\n",
    "    contours = measure.find_contours(sub_mask, 0.5)\n",
    "\n",
    "    segmentations = []\n",
    "    polygons = []\n",
    "    for contour in contours:\n",
    "        # Flip from (row, col) representation to (x, y)\n",
    "        # and subtract the padding pixel\n",
    "        for i in range(len(contour)):\n",
    "            row, col = contour[i]\n",
    "            contour[i] = (col - 1, row - 1)\n",
    "\n",
    "        # Make a polygon and simplify it\n",
    "        poly = Polygon(contour)\n",
    "        poly = poly.simplify(1.0, preserve_topology=False)\n",
    "        polygons.append(poly)\n",
    "        segmentation = np.array(poly.exterior.coords).ravel().tolist()\n",
    "        segmentations.append(segmentation)\n",
    "\n",
    "    # Combine the polygons to calculate the bounding box and area\n",
    "    multi_poly = MultiPolygon(polygons)\n",
    "    x, y, max_x, max_y = multi_poly.bounds\n",
    "    width = max_x - x\n",
    "    height = max_y - y\n",
    "    bbox = (x, y, width, height)\n",
    "    area = multi_poly.area\n",
    "\n",
    "    annotation = {\n",
    "        'segmentation': segmentations,\n",
    "        'iscrowd': is_crowd,\n",
    "        'image_id': image_id,\n",
    "        'category_id': category_id,\n",
    "        'id': annotation_id,\n",
    "        'bbox': bbox,\n",
    "        'area': area\n",
    "    }\n",
    "\n",
    "    return annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1244dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub_masks(mask_image):\n",
    "    width, height = mask_image.size\n",
    "\n",
    "    # Initialize a dictionary of sub-masks indexed by RGB colors\n",
    "    sub_masks = {}\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            # Get the RGB values of the pixel\n",
    "            pixel = mask_image.getpixel((x,y))[:3]\n",
    "\n",
    "            # If the pixel is not black...\n",
    "            if pixel != (0, 0, 0):\n",
    "                # Check to see if we've created a sub-mask...\n",
    "                pixel_str = str(pixel)\n",
    "                sub_mask = sub_masks.get(pixel_str)\n",
    "                if sub_mask is None:\n",
    "                   # Create a sub-mask (one bit per pixel) and add to the dictionary\n",
    "                    # Note: we add 1 pixel of padding in each direction\n",
    "                    # because the contours module doesn't handle cases\n",
    "                    # where pixels bleed to the edge of the image\n",
    "                    sub_masks[pixel_str] = Image.new('1', (width+2, height+2))\n",
    "\n",
    "                # Set the pixel value to 1 (default is 0), accounting for padding\n",
    "                sub_masks[pixel_str].putpixel((x+1, y+1), 1)\n",
    "\n",
    "    return sub_masks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
